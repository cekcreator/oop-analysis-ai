{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP Analysis of AI Software Frameworks\n",
    "Code Examples for all 4 frameworks. Each Framework will have an example of the OOP concept discussed in the paper\n",
    "* Inheritance\n",
    "* Polymorphism\n",
    "* Encapsulation\n",
    "* Abstraction\n",
    "\n",
    "Please run the cell below to be able to compile the code cells, it installs the neccesary packages into your conda env\n",
    "For some examples if you want to test the full functionality you will need access to a hosted service or LLM\n",
    "If you dont want to pay for tokens look at Ollama as it has great interoperability with LangChain/LangGraph and LLamaIndex, it uses smallers models like Llama 8b. The examples use the OpenAI GPT interface but it also works with models hosted on AWS/Azure and self hosted models as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (0.3.9)\n",
      "Requirement already satisfied: langchain_community in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (0.3.9)\n",
      "Requirement already satisfied: langgraph in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (0.2.55)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.56-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: transformers in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: llama-index in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: elasticsearch in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (8.16.0)\n",
      "Requirement already satisfied: torch in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (3.11.9)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (0.3.21)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain_community) (2.6.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langgraph) (2.0.8)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langgraph) (0.1.42)\n",
      "Requirement already satisfied: filelock in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.12.2)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.3.2)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from elasticsearch) (8.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.2.3)\n",
      "Requirement already satisfied: certifi in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.8.30)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.56.2)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.6.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (11.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.8.0)\n",
      "Requirement already satisfied: wrapt in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.6)\n",
      "Requirement already satisfied: pandas in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.16)\n",
      "Requirement already satisfied: click in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: anyio in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/calebkumar/anaconda3/envs/code_examples/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
      "Downloading langgraph-0.2.56-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: langgraph\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 0.2.55\n",
      "    Uninstalling langgraph-0.2.55:\n",
      "      Successfully uninstalled langgraph-0.2.55\n",
      "Successfully installed langgraph-0.2.56\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from PIL.ImageChops import add_modulo\n",
    "from transformers.models.cvt.convert_cvt_original_pytorch_checkpoint_to_pytorch import attention\n",
    "%pip install -U langchain langchain_community langgraph transformers llama-index elasticsearch torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:44:14.726699Z",
     "start_time": "2024-12-06T18:44:14.395923Z"
    }
   },
   "source": [
    "\"\"\"Imports Needed for code to run\"\"\"\n",
    "from transformers import PreTrainedModel, GPT2Model\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "from transformers import GPT2Config\n",
    "from transformers import GPT2Config, GPT2Tokenizer\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inheritance\n",
    "Through inheriting the base GPT2Model we can then create a custom forward pass while still retaining needed functionality"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:54:12.246272Z",
     "start_time": "2024-12-06T18:54:05.179957Z"
    }
   },
   "source": [
    "class CustomGPT2(GPT2Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        # Override the forward method to add custom behavior like the below scaling of logits\n",
    "        outputs = super().forward(input_ids, attention_mask)\n",
    "        logits = outputs.last_hidden_state\n",
    "        return logits * 0.5  # custom logits\n",
    "\n",
    "\n",
    "\"\"\"Uncomment below to run the full code, may take sometime to run machine dependant\"\"\"\n",
    "# config = GPT2Config()\n",
    "# custom_model = CustomGPT2(config)\n",
    "#\n",
    "# # tokenize input\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# input_text = \"Hugging Face models are powerful!\"\n",
    "# inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "#\n",
    "# outputs = custom_model.forward(input_ids=inputs[\"input_ids\"])\n",
    "# print(\"Scaled logits shape:\", outputs.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([1, 7])\n",
      "Attention Mask shape: torch.Size([1, 7])\n",
      "Scaled logits shape: torch.Size([1, 7, 768])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymorphism through AutoModel\n",
    "\n",
    "AutoModel can handle any/most models hosted on huggingface and provide a simple same interface for all model interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: bert-base-uncased with 768 hidden units.\n",
      "Loaded model: gpt2 with 768 hidden units.\n",
      "Loaded model: distilbert-base-uncased with 768 hidden units.\n"
     ]
    }
   ],
   "source": [
    "# Using the same interface for different model types\n",
    "models = [\"bert-base-uncased\", \"gpt2\", \"distilbert-base-uncased\"]\n",
    "for model_name in models:\n",
    "    model = AutoModel.from_pretrained(model_name)  # Polymorphism here \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    print(f\"Loaded model: {model_name} with {model.config.hidden_size} hidden units.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstraction\n",
    "With abstracting complex pipeline logic away for sentiment analysis, like tokenization and more we can simply use the interfaces for quick sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998284578323364}]\n"
     ]
    }
   ],
   "source": [
    "# Hiding complex logic of a model behind a simple interface\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "results = classifier(\"Hugging Face makes machine learning fun!\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Analyzers from Inheritance\n",
    "Below is a custom analyzer that inherits standard behavior but creates custom logic for using different filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_analyzer_with_inheritance = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "        \"analyzer\": {\n",
    "            \"custom_analyzer\": {\n",
    "            \"type\": \"custom\",\n",
    "            \"tokenizer\": \"standard\",\n",
    "            \"filter\": [\"lowercase\", \"asciifolding\"]\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    }\n",
    " }\n",
    "\n",
    "\"\"\"Uncomment below after you have followed the ElasticSearch instruction\"\"\"\n",
    "# es = Elasticsearch(hosts=[])\n",
    "# index_name = \"temp_index\"\n",
    "#\n",
    "# response = es.indices.create(index=index_name, body=custom_analyzer_with_inheritance)\n",
    "# print(\"Index created:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymorphism through interfaces with query logic\n",
    "Below is an example of DSL, the ES custom query language, where we define different queries like bool/must within the same query object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_logic_with_polymorphism = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "        \"must\": [\n",
    "            { \"match\": { \"title\": \"Elasticsearch\" } },\n",
    "            { \"range\": { \"date\": { \"gte\": \"2022-01-01\" } } }\n",
    "        ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\"Uncomment below after you have followed the ElasticSearch instruction\"\"\"\n",
    "# es = Elasticsearch(hosts=[])\n",
    "# index_name = \"temp_index2\"\n",
    "#\n",
    "# response = es.indices.create(index=index_name, body=custom_analyzer_with_inheritance)\n",
    "# print(\"Index created:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulation through hiding query logic and formatting\n",
    "To fully run the below code you need to have access to a cloud where your service is hosted (or localhost) so here is the basic class structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Usage below if a hosting service is used'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SearchService:\n",
    "    def __init__(self, es_client):\n",
    "        self.es = es_client\n",
    "\n",
    "    def search_by_title(self, index, title):\n",
    "        query = {\n",
    "            \"query\": {\n",
    "                \"match\": {\"title\": title}\n",
    "            }\n",
    "        }\n",
    "        return self.es.search(index=index, body=query)\n",
    "\n",
    "\"\"\"Usage below if a hosting service is used\"\"\"\n",
    "# es = Elasticsearch(host=[], cloud_id=\"\", auth=\"\")\n",
    "# search_service = SearchService(es)\n",
    "# response = search_service.search_by_title(\"temp_index\", \"Elasticsearch\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstraction through hiding complex bulk indexing or distributed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Usage below if a hosting service is used'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BulkIndexer:\n",
    "    def __init__(self, es_client, index):\n",
    "        self.es = es_client\n",
    "        self.index = index\n",
    "\n",
    "    def index_documents(self, docs):\n",
    "        actions = [\n",
    "            {\n",
    "                \"_index\": self.index,\n",
    "                \"_id\": doc[\"id\"],\n",
    "                \"_source\": doc\n",
    "            }\n",
    "            for doc in docs\n",
    "        ]\n",
    "        bulk(self.es, actions)\n",
    "\n",
    "\"\"\"Usage below if a hosting service is used\"\"\"\n",
    "# es = Elasticsearch(host=[], cloud_id=\"\", auth=\"\")\n",
    "# indexer = BulkIndexer(es, \"temp_index\")\n",
    "\n",
    "# documents = [\n",
    "#     {\"id\": 1, \"title\": \"Elasticsearch Basics\"},\n",
    "#     {\"id\": 2, \"title\": \"Advanced Elasticsearch\"}\n",
    "# ]\n",
    "\n",
    "# indexer.index_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain/Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:07:08.223960Z",
     "start_time": "2024-12-06T19:07:06.965551Z"
    }
   },
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import Ollama\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from typing import Any, List\n",
    "import requests"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inheritance\n",
    "Inherits the base LLMChain class to have the basic chaining functionality but allows devs to extend logic like in the example below for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Need to connect to an LLM for this full thing to compile'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LoggingLLMChain(LLMChain):\n",
    "    def __init__(self, llm, prompt):\n",
    "        super().__init__(llm=llm, prompt=prompt)\n",
    "    \n",
    "    def _call(self, inputs):\n",
    "        inputs['text'] = inputs['text'].strip().lower()\n",
    "        print(f\"Input received: {inputs['text']}\")\n",
    "\n",
    "        result = super()._call(inputs)\n",
    "\n",
    "        print(f\"Model output: {result}\")\n",
    "        return result\n",
    "\n",
    "\"\"\"Need to connect to an LLM for this full thing to compile, this needs the ollama download to run\"\"\"\n",
    "# ollama_llm = Ollama(model=\"llama-2-13b-chat\", temperature=0.7)\n",
    "# prompt = PromptTemplate(template=\"Translate this to French: {text}\", input_variables=[\"text\"])\n",
    "# chain = LoggingLLMChain(llm=ollama_llm, prompt=prompt)\n",
    "#\n",
    "# inputs = {\"text\": \"I love pie\"}\n",
    "# response = chain.run(inputs)\n",
    "# print(f\"Final Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymorphism through tools and their shared interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class addition_tool(BaseTool):\n",
    "    name: str = \"addition_tool\"\n",
    "    description: str = \"Adds two numbers provided as input.\"\n",
    "\n",
    "    def _run(self, query: str):\n",
    "        try:\n",
    "            numbers = list(map(float, query.split()))\n",
    "            return f\"Sum: {sum(numbers)}\"\n",
    "        except ValueError:\n",
    "            return \"Invalid input. Provide two numbers separated by a space.\"\n",
    "\n",
    "\n",
    "class reverse_string_tool(BaseTool):\n",
    "    name: str = \"reverse_tool\"\n",
    "    description: str = \"Reverses the input string.\"\n",
    "\n",
    "    def _run(self, query: str):\n",
    "        return f\"Reversed: {query[::-1]}\"\n",
    "\n",
    "\n",
    "\"\"\"Need to connect to an LLM for this full thing to compile, this needs the ollama download to run\"\"\"\n",
    "# addition_tool = addition_tool()\n",
    "# reverse_tool = reverse_string_tool()\n",
    "#\n",
    "# tools = [\n",
    "#     Tool(name=addition_tool.name, func=addition_tool.run, description=addition_tool.description),\n",
    "#     Tool(name=reverse_tool.name, func=reverse_tool.run, description=reverse_tool.description),\n",
    "# ]\n",
    "#\n",
    "# llm = Ollama(model=\"llama-2-13b-chat\", temperature=0.7)\n",
    "# agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "#\n",
    "# response_1 = agent.run(\"What is the sum of 12 and 7?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstraction\n",
    "Heres an example of abstraction of prompting an LLM without having to create a base agent or most other logic heavy workflow concepts like tool nodes, and memory management. To run it you do need access to an LLM. Encapsulates all of the other logic processes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:19:13.345670Z",
     "start_time": "2024-12-06T19:19:13.191146Z"
    }
   },
   "source": [
    "prompt = PromptTemplate(template=\"Translate to French: {text}\", input_variables=[\"text\"])\n",
    "\n",
    "# llm = Ollama(model=\"llama-2-13b-chat\", temperature=0.7)\n",
    "# chain = LLMChain(llm=llm, prompt=prompt)\n",
    "# response = chain.run(text=\"Hello world!\")\n",
    "# print(response)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulation\n",
    "Here is how we can define a custom tool and encapsulate the custom logic in _run so that when devs define the tool for an llm to use it does not need to understand more functionality about the tool than what it knows from BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T19:20:02.028062Z",
     "start_time": "2024-12-06T19:20:01.685520Z"
    }
   },
   "source": [
    "class WeatherTool(BaseTool):\n",
    "    name: str = \"weather_tool\"\n",
    "    description: str = \"Provides current weather information for a given city.\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"returns the weather for a given city.\"\"\"\n",
    "        city = query.strip()\n",
    "        try:\n",
    "            api_key = \"YOUR_API_KEY\"\n",
    "            url = f\"http://api.weatherapi.com/v1/current.json?key={api_key}&q={city}\"\n",
    "            response = requests.get(url).json()\n",
    "            weather = response.get(\"current\", {}).get(\"condition\", {}).get(\"text\", \"Unknown\")\n",
    "            temp = response.get(\"current\", {}).get(\"temp_c\", \"Unknown\")\n",
    "            return f\"The weather in {city} is {weather} with a temperature of {temp}Â°C.\"\n",
    "        except Exception as e:\n",
    "            return f\"Failed to fetch weather data: {str(e)}\"\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstraction\n",
    "Above in polymorphism we see how we can define custom tools with predefined equal interfaces (inherited from base class) and here we see how the tool decorater can abstract the extra logic away for simple tool making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:45:18.973850Z",
     "start_time": "2024-12-06T20:45:16.582002Z"
    }
   },
   "source": [
    "from llama_index.core.indices.base import BaseIndex\n",
    "from llama_index.core.node_parser.node_utils import BaseNode \n",
    "# from llama_index.core.indices.base\n",
    "from llama_index.core.indices.keyword_table import KeywordTableIndex\n",
    "from llama_index.core import SimpleDirectoryReader"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomIndex(BaseIndex):\n",
    "    def __init__(self, documents):\n",
    "        super().__init__()\n",
    "        self.documents = documents\n",
    "        self.index_data = self.build_index(documents)\n",
    "    \n",
    "    def build_index(self, documents):\n",
    "        \"\"\"Custom method to create a basic index from documents.\"\"\"\n",
    "        index = {}\n",
    "        for doc_id, doc in enumerate(documents):\n",
    "            index[doc_id] = doc.text\n",
    "        return index\n",
    "    \n",
    "    def query(self, query_text):\n",
    "        \"\"\"Override the query method to perform a simple keyword search.\"\"\"\n",
    "        results = []\n",
    "        for doc_id, content in self.index_data.items():\n",
    "            if query_text.lower() in content.lower():\n",
    "                results.append((doc_id, content))\n",
    "        return results or \"No matches found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymorphism with indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordIndex(BaseIndex):\n",
    "    def query(self, query_text: str) -> str:\n",
    "        return f\"KeywordIndex found results for '{query_text}'.\"\n",
    "\n",
    "class PrefixIndex(BaseIndex):\n",
    "    def query(self, query_text: str) -> str:\n",
    "        return f\"PrefixIndex found results starting with '{query_text}'.\"\n",
    "\n",
    "def execute_query(index: BaseIndex, query_text: str) -> str:\n",
    "    \"\"\"Polymorphism in action: Query any index type.\"\"\"\n",
    "    return index.query(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulation\n",
    "Hides query logic away from interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleIndex(BaseIndex):\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents  \n",
    "\n",
    "    def query(self, query_text: str) -> str:\n",
    "        # Encapsulate search logic and ovveride query()\n",
    "        results = [doc for doc in self.documents if query_text.lower() in doc.lower()]\n",
    "        return results if results else \"No matches found.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstraction\n",
    "Abstraction through hiding query logic through a simple interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractIndex:\n",
    "    def __init__(self, documents: List[str]):\n",
    "        self.documents = documents\n",
    "\n",
    "    def query(self, query_text: str) -> str:\n",
    "        \"\"\"Abstracts the logic of querying.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement query() method.\")\n",
    "\n",
    "class KeywordIndex(AbstractIndex):\n",
    "    def query(self, query_text: str) -> str:\n",
    "        results = [doc for doc in self.documents if query_text.lower() in doc.lower()]\n",
    "        return results if results else \"No matches found.\"\n",
    "\n",
    "class PrefixIndex(AbstractIndex):\n",
    "    def query(self, query_text: str) -> str:\n",
    "        results = [doc for doc in self.documents if doc.lower().startswith(query_text.lower())]\n",
    "        return results if results else \"No matches found.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
